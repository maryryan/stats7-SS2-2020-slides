---
title: "Two Sample Inference"
subtitle: "Stats 7"
author: "Mary Ryan"
date: "Sept. 1, 2020"
institute: "University of California, Irvine"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "chocolate-fonts", "headerPosition.css"]#like lucy
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9'
      slideNumberFormat: "%current%"
    seal: false
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache=TRUE)
knitr::opts_chunk$set(fig.align='center', out.width="53%", warning=FALSE, fig.retina = 3)
```

```{r load libraries, include=FALSE, comment='#'}
#install.packages( 'tidyverse' )
#install.packages( 'readxl' )

library( tidyverse, quietly=T, warn.conflicts = F )
library( knitr, quietly=T, warn.conflicts = F )
library( readxl, quietly=T, warn.conflicts = F )
#library( tufte, quietly=T, warn.conflicts = F )
#library( quantmod, quietly=T, warn.conflicts = F )
library( WVPlots, quietly=T, warn.conflicts = F )
library(patchwork)

```

```{r reduce code spacing, include = FALSE}
hook1 <- function(x){ gsub("```\n*```r*\n*", "", x) }
hook2 <- function(x){ gsub("```\n+```\n", "", x) }
knit_hooks$set(document = hook2)
```

layout: true
class: 

<!-- Old footer font color: #00A895 -->
<!-- old footer background color: #383838 -->

<!-- footer -->
 <div style="position:fixed; bottom:10px; left:4px; font-size: 12pt; color: #2DD8A5; background-color: #545454; width:93.5%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mary Ryan</div> <!--&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -->
<div style="position:fixed; bottom:10px; left:500px; font-size: 12pt; color: #2DD8A5">Two Sample Inference</div> <!--&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -->
<div style="position:fixed; bottom:10px; right:92px; font-size: 12pt; color: #2DD8A5">Stats 7</div>

---

<div style="position:fixed; left:50px; right:50px; top:125px; padding:30px; margin:auto; background-color:#C0F3E4; border-radius:15px">
<p>This class is being conducted over Zoom. As the instructor, I will be .alert[recording] this session. I have disabled the recording feature for others so that no one else will be able to record this session. I will be posting this session to the course’s website.</p>

<p>If you have privacy concerns and .alert[do not wish to appear in the recording], you may turn video off (click .alert[“stop video”]) so that Zoom does not record you.</p>

<p>The chat box is always open for discussion and questions to the entire class. You may also send messages privately to the instructor or the TAs. Please note that Zoom saves all chat transcripts.</p>

<p>I create a live transcription of each session using <a href="https://otter.ai/">Otter.ai</a>. This means that Otter.ai will transcribe anything spoken over the Zoom audio. The transcript will be posted with the session video on the course website.</p>
</div>

---

# Some Notes About Week 5 & Finals Week

- Final exam is next .alert[**Tuesday, Sept. 8 @ 1 p.m. PST**]
   - If you've arranged with me to take the exam at an alternate time, you should've heard from me within the last 72 hours
   - If you .alert[**have not**] heard from me and cannot make the original time, .alert[**email me as soon as possible**]
   
- Discussion Lab 5 this Friday will be a review. The discussion section will be recorded.

- Deadline to change grade option to pass/no pass is Friday, Sept. 4

- All extra credit work due by Tuesday, Sept. 8 @ 1 p.m. PST
   
- Finals week OH:
   - Mary
      - Sat., Sept. 5 @ 6 - 8 p.m. PST
   - Kyle
      - Sun., Sept. 6 @ 7:30 - 8:30 p.m. PST
      - Mon., Sept. 7 @ 7 - 9 p.m. PST
   - Jenifer
      - Fri., Sept. 5 @ 2 - 4 p.m. PST
      - Mon., Sept. 7 @ 2 - 4 p.m. PST

---

class: title-slide2

# <center> Two Sample Inference </center>
## <center> Stats 7 </center>
### <center> Mary Ryan </center>
### .center[Sept. 1, 2020]

<!-- social media info -->
<div style="position:fixed; bottom:40px; left:70px;">
<p><img src="https://du11hjcvx0uqb.cloudfront.net/br/dist/images/favicon-e10d657a73.ico" width="35"/> Course website:</p>
<p><a href="https://canvas.eee.uci.edu/courses/28451"> https://canvas.eee.uci.edu/courses/28451 </a></p>

<p><img src="https://svgsilh.com/svg/1873373.svg" width="35"/> Slides can be found at:</p>
</p><a href="https://maryryan.github.io/stats7-SS2-2020-slides/stats7-SS2-2020-twoSampleInference/stats7-SS2-2020-twoSampleInference"> https://maryryan.github.io/stats7-SS2-2020-slides/stats7-SS2-2020-twoSampleInference/stats7-SS2-2020-twoSampleInference </a></p>
</div>

---

# Learning Objectives

By the end of today's lecture, you should be able to:

- calculate and interpret confidence intervals for the true difference of means/proportions

- perform two-sample difference-of-means/proportions hypothesis tests

- draw appropriate conclusions for two-sample hypothesis tests in the context of the problem

---

# Comparing Two Populations

- Last lecture, we worked with how we can infer information about a .alert2[**single**] population
   - What is a plausible range of values that the population mean might be, based on our sample data?
   - If we previously had an idea of what the population mean was equal to, is our sample data confirming or challenging that idea?
   
- But what if we have .alert2[**two**] populations and we want to compare them?
   - Difference in heights of males and females?
   - Difference in diabetes cases of Northern and Southern U.S.?
   - Difference in proportion of deaths in placebo and experimental groups?
   
- We might take a sample from one population, $X^{(1)}$, with a sample size of $n_1$, distributed with mean $\mu_1$ and standard deviation $\sigma_1$

- Then take a sample from another population, $X^{(2)}$, with sample size $n_2$, distributed with mean $\mu_2$ and standard deviation $\sigma_2$

- Generally, we .alert2[**want to compare the means**] of these populations: $\mu_1 - \mu_2$

---

# Central Limit Theorem for Differences of Means

- The sample mean of population $X^{(1)}$ is: $\bar{x}_1 = \frac{1}{n_1}\sum_{i=1}^{n_1}x^{(1)}_i$

- The sample mean of population $X^{(2)}$ is: $\bar{x}_2 = \frac{1}{n_2}\sum_{i=1}^{n_2}x^{(2)}_i$

- We can .alert2[**estimate the difference**] in population means as: $\bar{x}_1 - \bar{x}_2$

- Because we are taking samples, there is going to be some variability around what what this difference actually is
   - The variance of the difference is: $\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}$
   - The standard deviation of the difference is: $\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}$
   
---

# Central Limit Theorem for Differences of Means

- Just like how we could use .alert[**Central Limit Theorem**] to approximate the sampling distribution of a single sample mean, we can use the same theorem to approximate the sampling distribution of the .alert2[**difference between sample means**]:

.center[
.content-box-teal[

$$(\bar{x}_1 - \bar{x}_2) \sim \text{Normal}\left(\text{mean = }\mu_1 - \mu_2, \text{variance = }\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2} \right)$$

or 

$$Z = \frac{(\bar{x}_1 - \bar{x}_2) - (\mu_1 - \mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}} \sim \text{Normal}\left(\text{mean = }0, \text{variance = }1 \right)$$
]
]

- Remember: we sometimes refer to the standard deviation of the sampling distribution as the .alert[**standard error**]
   - Here, standard error is: $\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}$

---

# 95% Confidence Intervals for Differences of Means

- This means we can get a .alert2[**plausible range of values**] for the difference between the two population means

- Remember from one-sample inference, we thought a plausible range of values might be the .alert2[**middle 95% of the sampling distribution**] of the sample mean $\bar{x}$:
$$\bar{x} \sim \text{Normal}(\text{mean}=\mu, \text{variance}=\frac{\sigma^2}{n}) \Rightarrow P(a < \bar{x} < b) = 0.95$$

- We'll use the same logic here

- A plausible range of values might be the middle 95% of the .alert2[**sampling distribution of the difference of the sample means**] ( $\bar{x}_1 - \bar{x}_2$ ):
$$(\bar{x}_1 - \bar{x}_2) \sim \text{Normal}\left(\text{mean = }\mu_1 - \mu_2, \text{variance = }\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2} \right)$$
$$P(a < \bar{x}_1 - \bar{x}_2 < b) = 0.95$$

- What were *a* and *b* for a one-sample 95% confidence interval? 1.96 standard errors above and below the sample mean

---

# Two-Sample 95% Confidence Intervals

- *a* and *b* for a two-sample 95% confidence interval will also be 1.96 .alert[**standard errors**] above and below the difference of the sample means:

$$P \left(-1.96\color{red}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}} < \bar{x}_1 - \bar{x}_2 < 1.96\color{red}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}} \right) = 0.95$$

- So you can calculate the .alert[**95% confidence interval for the difference of means**] to be:
.center[
.content-box-teal[
$$\left( [\bar{x}_1 - \bar{x}_2] - 1.96 \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}, [\bar{x}_1 - \bar{x}_2] + 1.96 \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}} \right)$$
]
]


- The .alert[**margin of error**] is now: $1.96 \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}$


---

# Two-Sample 95% Confidence Intervals

.content-box-teal[
.center[
**"We are 95% confident that the interval**

$$\left( [\bar{x}_1 - \bar{x}_2] - 1.96 \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}, [\bar{x}_1 - \bar{x}_2] + 1.96 \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}} \right)$$

**captures/contains the true difference in population means."**
]
]

- We can shorthand this to:

$$(\bar{x}_1 - \bar{x}_2) \pm 1.96 \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}$$

---

# Calculator: 2-SampZInterval

To get to the calculator function on a TI-84:
- STAT > TESTS > 9: 2-SampZInterval

To calculate confidence interval:
- input:
   - population 1 standard deviation ( $\sigma_1$ )
   - population 2 standard deviation ( $\sigma_2$ )
   - sample mean for population 1 ( $\bar{x}_1$ )
   - sample size for population 1 ( $n_1$ )
   - sample mean for population 2 ( $\bar{x}_2$ )
   - sample size for population 2 ( $n_2$ )
   - confidence level (C-Level)
- then arrow down to CALCULATE and press ENTER

---

# Example: Calculus Exam

Suppose in random sample of 40 college juniors and 30 college seniors, the mean score on a calculus exam is 75.3 for the juniors and 80.1 for the seniors. Suppose we also know that the population standard deviation for juniors is 10, and 11 for seniors.

- Calculate a 95% confidence interval for the true difference in mean exam scores.

---

# General Two-Sample Confidence Intervals

- Can write confidence interval formula generally as:

$$(\bar{x}_1 - \bar{x}_2) \pm Z^*_{\frac{1}{2}(1-\text{confidence})} \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}$$
.center[
**"We are XX% confident that the interval**

$$\left( [\bar{x}_1 - \bar{x}_2] - Z^*_{\frac{1}{2}(1-\text{confidence})} \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}, [\bar{x}_1 - \bar{x}_2] + Z^*_{\frac{1}{2}(1-\text{confidence})} \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}} \right)$$

**captures/contains the true difference in population means."**
]

- Margin of error is now: $Z^*_{\frac{1}{2}(1-\text{confidence})} \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}$

---

# Example: Calculus Exam

Suppose in random sample of 40 college juniors and 30 college seniors, the mean score on a calculus exam is 75.3 for the juniors and 80.1 for the seniors. Suppose we also know that the population standard deviation for juniors is 10, and 11 for seniors.

- Calculate a 99% confidence interval for the true difference in mean exam scores.

---

# Two-Sample Confidence Intervals with Sample Variances

- What if we don’t know the true population variances or standard deviations?
   - We substitute in $s^2_1$ for $\sigma^2_1$, and $s^2_2$ for $\sigma^2_2$
   
- Then we know:

$$T = \frac{(\bar{x}_1 - \bar{x}_2) - (\mu_1 - \mu_2)}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}} \sim T(\text{degrees of freedom} = n_1 + n_2 - 2)$$

- Then we can write a confidence interval as:
$$(\bar{x}_1 - \bar{x}_2) \pm T^*_{\frac{1}{2}(1-\text{confidence}),  df=(n_1+n_2 - 2)} \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}$$
---

# Calculator: 2-SampTInterval

To get to the calculator function on a TI-84:
- STAT > TESTS > 0: 2-SampZInterval

To calculate confidence interval:
- input:
   - sample mean for population 1 ( $\bar{x}_1$ )
   - population 1 standard deviation ( $S_{x1}$ )
   - sample size for population 1 ( $n_1$ )
   - sample mean for population 2 ( $\bar{x}_2$ )
   - population 2 standard deviation ( $S_{x2}$ )
   - sample size for population 2 ( $n_2$ )
   - confidence level (C-Level)
- then arrow down to CALCULATE and press ENTER

---

# Example: Diabetes & White Blood Cells

We would like to know if there is a difference in the amount of white blood cell counts in type 1 and type 2 diabetics. We draw blood from 40 type 1 diabetics and 42 type 2 diabetics. Type 1 diabetics had a mean count of 8,548 per mcL of blood, with a sample standard deviation of 306. Type 2 diabetics had a mean count of 13,257 per mcL of blood, with sample standard deviation of 253.

- What is a 95% confidence interval for the difference in mean cell counts between type 2 and type 2 diabetics?

---

# Two-Sample Confidence Intervals with Proportions

- We can extend this to comparing two populations where the data comes from a survey
   - Asking men and women the same yes/no survey question

- The sample proportion $\hat{p}_1$ is used to estimate the proportion in the first population that has a sample size of $n_1$

- The sample proportion $\hat{p}_2$ is used to estimate the proportion in the second population that has a sample size of $n_2$

- We can then say:
$$(\hat{p}_1 - \hat{p}_2) \sim \text{Normal} \left(\text{mean} = (p_1 - p_2), \text{variance} = \frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}\right)$$

or

$$Z = \frac{(\hat{p}_1 - \hat{p}_2) - (p_1 - p_2)}{\sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}} \sim \text{Normal}(\text{mean} = 0, \text{variance} = 1)$$

---

# Two-Sample Confidence Intervals with Proportions

- Then we can write a confidence interval as:
$$(\hat{p}_1 - \hat{p}_2) \pm Z^*_{\frac{1}{2}(1-\text{confidence})} \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}$$

   - Notice that we're using $\hat{p}_1$ and $\hat{p}_2$ in the standard error
<br>
<br>

.center[
**"We are X% confident that the interval**

$$\left( (\hat{p}_1 - \hat{p}_2) - Z^*_{\frac{1}{2}(1-\text{confidence})} \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}, (\hat{p}_1 - \hat{p}_2) + Z^*_{\frac{1}{2}(1-\text{confidence})} \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}} \right)$$

**captures/contains the true difference in population proportions."**

]


---

# Calculator: 2-PropZInt

To get to the calculator function on a TI-84:
- STAT > TESTS > B: 2-PropZInterval

To calculate confidence interval:
- input:
   - number of observations with trait from sample 1 ( $x_1$ )
   - sample size for population 1 ( $n_1$ )
   - number of observations with trait from sample 2 ( $x_2$ )
   - sample size for population 2 ( $n_2$ )
   - confidence level (C-Level)
- then arrow down to CALCULATE and press ENTER


---

# Example: Hip Dysplasia

Studies have shown that hip dysplasia, a semi-genetic disorder where the femur doesn’t correctly fit into the hip socket, is more common in larger dog breeds. To investigate this, we test 27 Great Danes (large), 34 Shih Tzus (small), 41 Shiba Inus (medium) for the disorder. We find that 4 Great Danes, 7 Shih Tzus, and 2 Shiba Inus are dysplastic.

- What are the proportions of each breed that have hip dysplasia?

<br>

- What is a 90% confidence interval for the difference in dysplasia rates between Great Danes and Shih Tzus?


---

# Hypothesis Test for Difference in Means

- In last lecture where we tested our preconceived notions about what the mean of a single population was

- We can do the same thing with testing our ideas about the relationship between the means of 2 populations


---

# Step 1: State your Hypotheses

.pull-left[
**For Means**

- Is the difference between the population means .alert2[**not equal**] to some value $\mu_0$?
   - $H_0: \mu_1 - \mu_2 = \mu_0$
   - $H_A: \mu_1 - \mu_2 \ne \mu_0$
   
- Is the difference between the population means .alert2[**greater than**] some value $\mu_0$?
   - $H_0: \mu_1 - \mu_2 \le \mu_0$
   - $H_A: \mu_1 - \mu_2 > \mu_0$
   
- Is the difference between the population means .alert2[**less than**] some value $\mu_0$?
   - $H_0: \mu_1 - \mu_2 \ge \mu_0$
   - $H_A: \mu_1 - \mu_2 < \mu_0$
   
]

.pull-right[
**For Proportions**

- Is the difference between the population means .alert2[**not equal**] to some value $p_0$?
   - $H_0: p_1 - p_2 = p_0$
   - $H_A: p_1 - p_2 \ne p_0$
   
- Is the difference between the population proportions .alert2[**greater than**] some value $p_0$?
   - $H_0: p_1 - p_2 \le p_0$
   - $H_A: p_1 - p_2 > p_0$
   
- Is the difference between the population proportions .alert2[**less than**] some value $p_0$?
   - $H_0: p_1 - p_2 \ge p_0$
   - $H_A: p_1 - p_2 < p_0$

]

---

# Step 2: Calculate your Test Statistic

- If we know the .alert2[**population**] standard deviations:

.center[
$z = \frac{(\bar{x}_1 - \bar{x}_2) - \mu_0}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}},$     $z = \frac{(\hat{p}_1 - \hat{p}_2) - p_0}{\sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}}$
]


- If we're estimating the population standard deviations with the .alert2[**sample**] standard deviations:
$$t = \frac{(\bar{x}_1 - \bar{x}_2) - \mu_0}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}$$
.content-box-teal[
.center[
**"If the null hypothesis was true, this is how many standard deviations away from the null hypothesis difference the difference between our sample means is"**
]
]

---

# Step 2: Calculate your Test Statistic

- If $H_0: p_1 - p_2 = 0$, we need to "average" the two proportions together to get the standard error:

$$z = \frac{(\hat{p_1} - \hat{p}_2) - 0}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n_1} + \frac{\hat{p}(1-\hat{p})}{n_2}}}$$
$$\hat{p} = \frac{\hat{p}_1n_1 + \hat{p}_2n_2}{n_1 + n_2}$$

---

# Step 3: Find Your Critical Value/Calculate Your P-value

A critical value ( $Z^*$ or $T^*$ ) is the value your test statistic would have to surpass in order for you to reject $H_0$

- If $H_A: \ne$ (two-sided), use the Z- or T-table to find a critical value that has some small probability (usually **0.025**) to the .alert2[**right**] (i.e., P(Z>z^*) = 0.025 )
   
<br>
<br>
<br>
   
   - If $H_A: <$ (one-sided), use the Z- or T-table to find a critical value that has some small probability (usually **0.05**) to the .alert2[**left**] (i.e., P(Z<z^*) = 0.05 )
   
<br>
<br>
<br>
   
   - If $H_A: >$ (one-sided), use the Z- or T-table to find a critical value that has some small probability (usually **0.05**) to the .alert2[**right**] (i.e., P(Z>z^*) = 0.05 )

---

# Step 3: Find Your Critical Value/Calculate Your P-value

To calculate p-value:

- If $H_A: \ne$ (two-sided):
$$\text{p-value} = 2\times P(Z>|\text{test-statistic}|)$$
$$\text{p-value} = 2\times P(T>|\text{test-statistic}|)$$

   
- If $H_A: <$ (one-sided):
$$\text{p-value} = P(Z<\text{test-statistic})$$
$$\text{p-value} = P(T<\text{test-statistic})$$

   
- If $H_A: >$ (one-sided):
$$\text{p-value} = P(Z>\text{test-statistic})$$
$$\text{p-value} = P(T>\text{test-statistic})$$



---

# Step 4: Draw a conclusion


- For $H_A: \ne$ (two-sided) test:
   - If |test-statistic| > critical value, __reject__ the null
   - If |test-statistic| < critical value, __fail to reject__ the null
   
- For one-sided test:
   - $H_A: >$
      - If test-statistic > critical value, **reject** the null
      - If test-statistic < critical value, **fail to reject** the null
      
   - $H_A: <$
      - If test-statistic < critical value, **reject** the null
      - If test-statistic > critical value, **fail to reject** the null
      
- For any test:
   - If p-value is "small" (<0.05), **reject** the null
   - If p-value is "not small" (>0.05), **fail to reject** the null


---

# Step 5: Interpret your conclusion in context

- For a rejection

   - Why are we rejecting?
   - What strength of evidence do we have?
   - What does a rejection of the null hypothesis mean for our knowledge about the populations?

- For a fail-to-reject

   - Why are we not rejecting?
   - Was our evidence not very strong?
   - What does a failure to reject the null hypothesis mean for our knowledge about the populations?

---

# Calculator: 2-SampZTest

To get to the calculator function on a TI-84:
- STAT > TESTS > 3: 2-SampZTest

To calculate hypothesis test statistic and p-value:
- input:
   - population 1 standard deviation ( $\sigma_1$ )
   - population 2 standard deviation ( $\sigma_2$ )
   - sample mean from population 1( $\bar{x}_1$ )
   - sample size from population 1 ( $n_1$ )
   - sample mean from population 2( $\bar{x}_2$ )
   - sample size from population 2 ( $n_2$ )
   - direction of test: ( $\mu_1: \ne \mu_2, < \mu_2, > \mu_2$ )
- then arrow down to CALCULATE and press ENTER

---

# Calculator: 2-SampTTest

To get to the calculator function on a TI-84:
- STAT > TESTS > 4: 2-SampTTest

To calculate hypothesis test statistic and p-value:
- input:
   - sample mean from population 1( $\bar{x}_1$ )
   - sample 1 standard deviation ( $S_{x1}$ )
   - sample size from population 1 ( $n_1$ )
   - sample mean from population 2( $\bar{x}_2$ )
   - sample 2 standard deviation ( $S_{x2}$ )
   - sample size from population 2 ( $n_2$ )
   - direction of test: ( $\mu_1: \ne \mu_2, < \mu_2, > \mu_2$ )
   - Pooled: always select "No"
- then arrow down to CALCULATE and press ENTER

---

# Example: Smoking & Birth Weight

We are researchers looking into the effects of pre-natal smoking (birth mother smoking during pregnancy) on birth weight of the baby. We gather data from 52 smoking mothers in North Carolina, and 100 non-smoking mothers. We want to know if babies whose moms smoked during pregnancy have different average birth weights than babies whose moms didn't smoke during pregnancy.

The babies from the smoking mothers had a mean birth weight of 6.78 lbs and a sample standard deviation of 1.43. The babies from non-smoking mothers had a mean birth weight of 7.18 lbs and a sample standard deviation of 160.

- State your null and alternative hypotheses.

--

$$H_0:  \mu_{NS} - \mu_{S} = 0\text{ (no difference in mean birth weights)}$$
$$H_0:  \mu_{NS} - \mu_{S} \ne 0\text{ (some difference in mean birth weights)}$$

---

# Example: Smoking & Birth Weight

We are researchers looking into the effects of pre-natal smoking (birth mother smoking during pregnancy) on birth weight of the baby. We gather data from 52 smoking mothers in North Carolina, and 100 non-smoking mothers. We want to know if babies whose moms smoked during pregnancy have different average birth weights than babies whose moms didn't smoke during pregnancy.

The babies from the smoking mothers had a mean birth weight of 6.78 lbs and a sample standard deviation of 1.43. The babies from non-smoking mothers had a mean birth weight of 7.18 lbs and a sample standard deviation of 1.60.

- Find your test statistic. Find a critical value or calculate the p-value.

---

# Example: Smoking & Birth Weight

We are researchers looking into the effects of pre-natal smoking (birth mother smoking during pregnancy) on birth weight of the baby. We gather data from 52 smoking mothers in North Carolina, and 100 non-smoking mothers. We want to know if babies whose moms smoked during pregnancy have different average birth weights than babies whose moms didn't smoke during pregnancy.

The babies from the smoking mothers had a mean birth weight of 6.78 lbs and a sample standard deviation of 1.43. The babies from non-smoking mothers had a mean birth weight of 7.18 lbs and a sample standard deviation of 160.

- Conclusion?


---

# Example: Car Repairs

A consumer advocacy group wants to find out if there's a difference between the proportions of two leading car models that need more the $500 worth of repairs within 2 years of their purchase. A sample of 400 owners of model A were contacted, and we find that 53 needed these major repairs. A sample of 500 owners of model B were also contacted, and we find that 78 needed these major repairs.

- State your null and alternative hypotheses.

--

$$H_0: p_A - p_B = 0\text{ (no difference in repair rates of 2 models)}$$
$$H_A: p_A - p_B \ne 0\text{ (the repair rate is different)}$$

---

# Example: Car Repairs

A consumer advocacy group wants to find out if there's a difference between the proportions of two leading car models that need more the $500 worth of repairs within 2 years of their purchase. A sample of 400 owners of model A were contacted, and we find that 53 needed these major repairs. A sample of 500 owners of model B were also contacted, and we find that 78 needed these major repairs.

- Find your test statistic. Find a critical value or calculate the p-value.


---

# Example: Car Repairs

A consumer advocacy group wants to find out if there's a difference between the proportions of two leading car models that need more the $500 worth of repairs within 2 years of their purchase. A sample of 400 owners of model A were contacted, and we find that 53 needed these major repairs. A sample of 500 owners of model B were also contacted, and we find that 78 needed these major repairs.

- Conclusion?
